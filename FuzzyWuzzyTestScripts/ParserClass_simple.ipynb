{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First Name Last Name        Street Address               City State    Zip  \\\n",
      "0   Isabella     Jones  No Address Indicated  No City Indicated    CA  99999   \n",
      "\n",
      "        DOB Gender                            Race  \\\n",
      "0  19470501      F  Caucasian or European American   \n",
      "\n",
      "                                           Allergies  \\\n",
      "0  Bicillin L-A Onset: Not Indicated Hives Very M...   \n",
      "\n",
      "                                       Immunizations  Procedures  \n",
      "0  tetanus toxoid, unspecified formulation 2007-0...         NaN  \n"
     ]
    }
   ],
   "source": [
    "def getRoot(file):\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    return root\n",
    "\n",
    "def parseDataToCSV(file):  \n",
    "    root = getRoot(file)\n",
    "    \n",
    "    infile = open(file,\"r\")\n",
    "    contents = infile.read()\n",
    "    soup = BeautifulSoup(contents,'xml')\n",
    "    \n",
    "    DemographicsCSV = open('demographic.csv', 'w')\n",
    "    csvwriter = csv.writer(DemographicsCSV)\n",
    "    headers = [\"First Name\", \"Last Name\", \"Street Address\", \"City\", \"State\", \"Zip\", \"DOB\", \"Gender\", \"Race\", \"Allergies\", \"Immunizations\", \"Procedures\"]\n",
    "    csvwriter.writerow(headers)\n",
    "    infoList = parseListFromRoot(root,soup)\n",
    "    csvwriter.writerow(infoList)\n",
    "    DemographicsCSV.close()\n",
    "    return 'demographic.csv'\n",
    "    \n",
    "def parseListFromRoot(root,soup):\n",
    "    names = []\n",
    "    #Parse first name(s)\n",
    "    for name in root.findall('.//{urn:hl7-org:v3}patient/{urn:hl7-org:v3}name/{urn:hl7-org:v3}given'):\n",
    "        names.append(name.text)\n",
    "    #Parse last name(s)\n",
    "    for name in root.findall('.//{urn:hl7-org:v3}patient/{urn:hl7-org:v3}name/{urn:hl7-org:v3}family'):\n",
    "        names.append(name.text)\n",
    "    #Parse addresses\n",
    "    for name in root.findall('.//{urn:hl7-org:v3}patientRole/{urn:hl7-org:v3}addr/{urn:hl7-org:v3}streetAddressLine'):\n",
    "        names.append(name.text)\n",
    "    #Parse city\n",
    "    for name in root.findall('.//{urn:hl7-org:v3}patientRole/{urn:hl7-org:v3}addr/{urn:hl7-org:v3}city'):\n",
    "        names.append(name.text)\n",
    "    #Parse state\n",
    "    for name in root.findall('.//{urn:hl7-org:v3}patientRole/{urn:hl7-org:v3}addr/{urn:hl7-org:v3}state'):\n",
    "        names.append(name.text)\n",
    "    #Parse postal code\n",
    "    for name in root.findall('.//{urn:hl7-org:v3}patientRole/{urn:hl7-org:v3}addr/{urn:hl7-org:v3}postalCode'):\n",
    "        names.append(name.text)\n",
    "    #Parse birthTime\n",
    "    birth = root.find('.//{urn:hl7-org:v3}patient/{urn:hl7-org:v3}birthTime')\n",
    "    names.append(birth.attrib[\"value\"])\n",
    "    #Parse gender\n",
    "    gender = root.find('.//{urn:hl7-org:v3}patient/{urn:hl7-org:v3}administrativeGenderCode')\n",
    "    names.append(gender.attrib[\"code\"])\n",
    "    #Parse race\n",
    "    race = root.find('.//{urn:hl7-org:v3}patient/{urn:hl7-org:v3}raceCode')\n",
    "    names.append(race.attrib[\"displayName\"])\n",
    "    #Parse allergies\n",
    "    names.append(parseOtherElements(soup,\"allergy\"))\n",
    "    #Parse immunizations\n",
    "    names.append(parseOtherElements(soup,\"immun\"))\n",
    "    #Parse procedures\n",
    "    names.append(parseOtherElements(soup,\"proc\"))\n",
    "    return names\n",
    "\n",
    "def parseOtherElements(soup,element):\n",
    "    strr = \"\"\n",
    "    tabled = soup.find_all('tr', {'ID':re.compile(element)})\n",
    "    for each in tabled: \n",
    "        temp = str(each.get_text()).split('\\n')\n",
    "        strr +=  ' '.join(list(filter(None, temp)))\n",
    "    return strr\n",
    "\n",
    "def printCSV(csv):\n",
    "    df = pd.read_csv(csv)\n",
    "    print(df.head(1))\n",
    "\n",
    "printCSV(parseDataToCSV('IsabellaJones-ReferralSummary.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
